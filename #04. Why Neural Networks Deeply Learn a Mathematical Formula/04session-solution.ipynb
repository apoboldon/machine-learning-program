{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+5\">#07. Why Neural Networks Deeply Learn a Mathematical Formula?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Book + Private Lessons [Here ‚Üó](https://sotastica.com/reservar)\n",
    "- Subscribe to my [Blog ‚Üó](https://blog.pythonassembly.com/)\n",
    "- Let's keep in touch on [LinkedIn ‚Üó](www.linkedin.com/in/jsulopz) üòÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Machine Learning, what does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - The Machine Learns...\n",
    ">\n",
    "> But, **what does it learn?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Machine Learning, what does it mean? ‚èØ<br><br>¬∑ The machine learns...<br><br>Ha ha, not funny! ü§® What does it learn?<br><br>¬∑ A mathematical equation. For example: <a href=\"https://t.co/sjtq9F2pq7\">pic.twitter.com/sjtq9F2pq7</a></p>&mdash; Jes√∫s L√≥pez (@sotastica) <a href=\"https://twitter.com/sotastica/status/1449735653328031745?ref_src=twsrc%5Etfw\">October 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Machine Learning, what does it mean? ‚èØ<br><br>¬∑ The machine learns...<br><br>Ha ha, not funny! ü§® What does it learn?<br><br>¬∑ A mathematical equation. For example: <a href=\"https://t.co/sjtq9F2pq7\">pic.twitter.com/sjtq9F2pq7</a></p>&mdash; Jes√∫s L√≥pez (@sotastica) <a href=\"https://twitter.com/sotastica/status/1449735653328031745?ref_src=twsrc%5Etfw\">October 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does the Machine Learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ht3rYS-JilE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ht3rYS-JilE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=329\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=329\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Practical Example ‚Üí [Tesla Autopilot](https://www.tesla.com/AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Example where It Fails ‚Üí [Tesla Confuses Moon with Semaphore](https://twitter.com/Carnage4Life/status/1418920100086784000?s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Simply execute the following lines of code to load the data.\n",
    "> - This dataset contains **statistics about Car Accidents** (columns)\n",
    "> - In each one of **USA States** (rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/fivethirtyeight/fivethirtyeight-bad-drivers-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VA</th>\n",
       "      <td>12.7</td>\n",
       "      <td>2.413</td>\n",
       "      <td>3.429</td>\n",
       "      <td>11.049</td>\n",
       "      <td>11.176</td>\n",
       "      <td>768.95</td>\n",
       "      <td>153.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WV</th>\n",
       "      <td>23.8</td>\n",
       "      <td>8.092</td>\n",
       "      <td>6.664</td>\n",
       "      <td>23.086</td>\n",
       "      <td>20.706</td>\n",
       "      <td>992.61</td>\n",
       "      <td>152.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>4.200</td>\n",
       "      <td>3.360</td>\n",
       "      <td>10.920</td>\n",
       "      <td>10.680</td>\n",
       "      <td>878.41</td>\n",
       "      <td>165.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ND</th>\n",
       "      <td>23.9</td>\n",
       "      <td>5.497</td>\n",
       "      <td>10.038</td>\n",
       "      <td>23.661</td>\n",
       "      <td>20.554</td>\n",
       "      <td>688.75</td>\n",
       "      <td>109.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>14.1</td>\n",
       "      <td>3.384</td>\n",
       "      <td>3.948</td>\n",
       "      <td>13.395</td>\n",
       "      <td>10.857</td>\n",
       "      <td>1110.61</td>\n",
       "      <td>152.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "VA       12.7     2.413    3.429          11.049       11.176       768.95   \n",
       "WV       23.8     8.092    6.664          23.086       20.706       992.61   \n",
       "CA       12.0     4.200    3.360          10.920       10.680       878.41   \n",
       "ND       23.9     5.497   10.038          23.661       20.554       688.75   \n",
       "MI       14.1     3.384    3.948          13.395       10.857      1110.61   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "VA          153.72  \n",
       "WV          152.56  \n",
       "CA          165.63  \n",
       "ND          109.72  \n",
       "MI          152.26  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(name='car_crashes', index_col='abbrev')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Concepts in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the `Weights`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "accidents = speeding \\cdot w_1 + alcohol \\cdot w_2 \\ + ... + \\ ins\\_losses \\cdot w_7\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_27075/22777151.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'algo' is not defined"
     ]
    }
   ],
   "source": [
    "algo.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`algo = ?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='zeros'))\n",
    "model.add(layer=Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-0.12113643],\n",
       "        [-0.7264997 ],\n",
       "        [-0.8376943 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         0.0\n",
       "AK       18.1         0.0\n",
       "AZ       18.6         0.0\n",
       "AR       22.4         0.0\n",
       "CA       12.0         0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265.9880392156863"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights to 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='ones'))\n",
    "model.add(layer=Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 12:00:31.417442: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[627.4761]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-0.82789993],\n",
       "        [ 0.53020895],\n",
       "        [ 0.940801  ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>627.476074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>792.735962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>678.492615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>657.208313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>690.185608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8  627.476074\n",
       "AK       18.1  792.735962\n",
       "AZ       18.6  678.492615\n",
       "AR       22.4  657.208313\n",
       "CA       12.0  690.185608"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457800.5573237031"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights to `glorot_uniform` (default)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 12:00:53.488202: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[164.4096]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.515978  ,  0.29486084, -0.24545974],\n",
       "        [-0.08075762, -0.4843331 , -0.55846286],\n",
       "        [-0.5519333 ,  0.3534726 ,  0.6272007 ],\n",
       "        [-0.22614557,  0.3294965 , -0.7274029 ],\n",
       "        [-0.50146097,  0.25734174,  0.03941071],\n",
       "        [ 0.7459314 , -0.79581195, -0.26785028]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-0.33921838],\n",
       "        [ 0.4942448 ],\n",
       "        [-1.0911044 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>164.409607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>238.960785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>208.966797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>179.851746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>176.044510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8  164.409607\n",
       "AK       18.1  238.960785\n",
       "AZ       18.6  208.966797\n",
       "AR       22.4  179.851746\n",
       "CA       12.0  176.044510"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32996.689520482854"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with the Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=558\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=558\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `sigmoid` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 22:28:07.667108: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29a13cc70>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.5038092 ,  0.59251285, -0.61746967],\n",
       "        [ 0.781296  , -0.80176395,  0.7765652 ],\n",
       "        [-0.23051041,  0.07111514, -0.17885393],\n",
       "        [ 0.77684414,  0.03942651,  0.7233834 ],\n",
       "        [-0.0752281 , -0.2436133 , -0.75898665],\n",
       "        [-0.7314203 ,  0.34452236,  0.56223965]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.66068447],\n",
       "        [-1.1992097 ],\n",
       "        [-1.0176677 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         1.0\n",
       "AK       18.1         1.0\n",
       "AZ       18.6         1.0\n",
       "AR       22.4         1.0\n",
       "CA       12.0         1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.4076470588235"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `linear` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 12:01:40.857784: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 7ms/step - loss: 870.0609 - mse: 870.0609\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 602.9550 - mse: 602.9550\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 510.5091 - mse: 510.5091\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 459.0305 - mse: 459.0305\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 430.5728 - mse: 430.5728\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 405.5358 - mse: 405.5358\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 397.5556 - mse: 397.5556\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 390.7502 - mse: 390.7502\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 383.9734 - mse: 383.9734\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 379.8975 - mse: 379.8975\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 373.3909 - mse: 373.3909\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 371.5401 - mse: 371.5401\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 366.7895 - mse: 366.7895\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 366.2645 - mse: 366.2644\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 360.0596 - mse: 360.0596\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 356.3292 - mse: 356.3292\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 353.2402 - mse: 353.2402\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 349.0797 - mse: 349.0797\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 346.1281 - mse: 346.1281\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 346.3060 - mse: 346.3060\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 341.1658 - mse: 341.1658\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 336.4924 - mse: 336.4923\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 331.9595 - mse: 331.9595\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 328.3994 - mse: 328.3994\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 328.8196 - mse: 328.8196\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 322.5959 - mse: 322.5959\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 320.2903 - mse: 320.2903\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 316.4254 - mse: 316.4254\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 311.7821 - mse: 311.7821\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 307.8217 - mse: 307.8217\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 306.4528 - mse: 306.4528\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 303.1884 - mse: 303.1884\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 305.3128 - mse: 305.3128\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 295.3603 - mse: 295.3603\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 291.9558 - mse: 291.9558\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 289.2619 - mse: 289.2619\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 292.5129 - mse: 292.5129\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 284.8651 - mse: 284.8651\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 292.5305 - mse: 292.5305\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 280.1522 - mse: 280.1522\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 276.0644 - mse: 276.0644\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 274.6501 - mse: 274.6501\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 270.3812 - mse: 270.3812\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 268.8108 - mse: 268.8108\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 265.5177 - mse: 265.5177\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 262.0154 - mse: 262.0154\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 259.7570 - mse: 259.7570\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 256.1454 - mse: 256.1454\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 253.2449 - mse: 253.2449\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 252.2786 - mse: 252.2786\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 248.2119 - mse: 248.2119\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 246.2759 - mse: 246.2759\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 242.5327 - mse: 242.5327\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 239.5662 - mse: 239.5662\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 236.7866 - mse: 236.7866\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 239.6564 - mse: 239.6564\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 232.8277 - mse: 232.8277\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 231.6901 - mse: 231.6901\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 226.8334 - mse: 226.8334\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 223.7213 - mse: 223.7213\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 221.3162 - mse: 221.3162\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 226.6135 - mse: 226.6135\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 217.6906 - mse: 217.6906\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 220.5236 - mse: 220.5236\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 213.3838 - mse: 213.3838\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 210.4027 - mse: 210.4027\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 213.6917 - mse: 213.6917\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 206.6797 - mse: 206.6797\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 204.7972 - mse: 204.7972\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 201.9936 - mse: 201.9936\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 200.4239 - mse: 200.4239\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 210.3002 - mse: 210.3002\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 198.0242 - mse: 198.0242\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 195.1421 - mse: 195.1421\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 191.8952 - mse: 191.8952\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 190.4053 - mse: 190.4053\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 188.0939 - mse: 188.0939\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 186.2063 - mse: 186.2063\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 184.8053 - mse: 184.8053\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 184.1654 - mse: 184.1654\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 183.0022 - mse: 183.0022\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 181.9711 - mse: 181.9711\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 176.8110 - mse: 176.8110\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 175.1419 - mse: 175.1419\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 173.3275 - mse: 173.3275\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 176.0948 - mse: 176.0948\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 170.2951 - mse: 170.2951\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 168.8809 - mse: 168.8809\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 165.9964 - mse: 165.9964\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 164.8650 - mse: 164.8650\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 163.0267 - mse: 163.0267\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 164.8092 - mse: 164.8092\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 159.8545 - mse: 159.8545\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 157.2236 - mse: 157.2236\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 155.2086 - mse: 155.2086\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 153.6804 - mse: 153.6804\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 152.0121 - mse: 152.0121\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 150.3281 - mse: 150.3281\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 149.9612 - mse: 149.9612\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 148.2743 - mse: 148.2743\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 149.7057 - mse: 149.7057\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 145.9393 - mse: 145.9393\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 145.5961 - mse: 145.5961\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 141.7955 - mse: 141.7955\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 141.4357 - mse: 141.4357\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 140.8239 - mse: 140.8239\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 138.4669 - mse: 138.4669\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 136.3506 - mse: 136.3506\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 133.7901 - mse: 133.7901\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 132.5179 - mse: 132.5179\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 131.5208 - mse: 131.5208\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 129.6552 - mse: 129.6551\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 127.9030 - mse: 127.9030\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 126.4214 - mse: 126.4214\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 125.0360 - mse: 125.0360\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 127.2946 - mse: 127.2946\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 127.0023 - mse: 127.0023\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 122.1864 - mse: 122.1864\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 119.8831 - mse: 119.8831\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 119.4621 - mse: 119.4621\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 121.5338 - mse: 121.5338\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 118.7294 - mse: 118.7294\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 116.8357 - mse: 116.8357\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 115.8617 - mse: 115.8617\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 112.8239 - mse: 112.8239\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 111.8533 - mse: 111.8533\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 110.9070 - mse: 110.9070\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 109.5313 - mse: 109.5313\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 109.1941 - mse: 109.1941\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 110.9277 - mse: 110.9277\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 107.7978 - mse: 107.7978\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 105.9825 - mse: 105.9825\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 104.7283 - mse: 104.7283\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 103.7740 - mse: 103.7740\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 102.0872 - mse: 102.0872\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 101.4858 - mse: 101.4858\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 100.0139 - mse: 100.0139\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 106.1789 - mse: 106.1789\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 98.5825 - mse: 98.5825\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 97.3675 - mse: 97.3675\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 96.1965 - mse: 96.1965\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 95.0553 - mse: 95.0553\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 94.2753 - mse: 94.2752\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 93.2611 - mse: 93.2611\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 92.2602 - mse: 92.2602\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 92.7567 - mse: 92.7567\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 91.9934 - mse: 91.9934\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 90.0137 - mse: 90.0137\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 89.6993 - mse: 89.6993\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 87.8308 - mse: 87.8308\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 88.4683 - mse: 88.4683\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 86.0312 - mse: 86.0312\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 85.2463 - mse: 85.2463\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 84.5366 - mse: 84.5366\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 83.6088 - mse: 83.6088\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 84.1215 - mse: 84.1215\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 82.3160 - mse: 82.3160\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 81.0118 - mse: 81.0118\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 80.2237 - mse: 80.2237\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 83.4774 - mse: 83.4774\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 79.3014 - mse: 79.3014\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 78.1296 - mse: 78.1296\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 77.2458 - mse: 77.2458\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 76.2202 - mse: 76.2202\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 76.2858 - mse: 76.2858\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 75.3610 - mse: 75.3610\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 74.3122 - mse: 74.3122\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 73.3015 - mse: 73.3015\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 74.4600 - mse: 74.4600\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 74.1380 - mse: 74.1380\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 71.8037 - mse: 71.8037\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 72.1754 - mse: 72.1754\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 70.2318 - mse: 70.2318\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 70.0907 - mse: 70.0907\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 69.1602 - mse: 69.1602\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 69.6681 - mse: 69.6681\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 67.8005 - mse: 67.8005\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 68.3372 - mse: 68.3372\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 67.1357 - mse: 67.1357\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 66.4309 - mse: 66.4309\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 67.4119 - mse: 67.4119\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 65.2767 - mse: 65.2767\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 64.4192 - mse: 64.4192\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 64.1806 - mse: 64.1806\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 63.1978 - mse: 63.1978\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 63.1124 - mse: 63.1124\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 62.2835 - mse: 62.2835\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 61.8916 - mse: 61.8916\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 60.8613 - mse: 60.8613\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 60.4121 - mse: 60.4121\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 59.8483 - mse: 59.8483\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 59.0497 - mse: 59.0497\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 58.5689 - mse: 58.5689\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 60.6919 - mse: 60.6919\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 57.7259 - mse: 57.7259\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 57.4250 - mse: 57.4250\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 56.4855 - mse: 56.4855\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 56.1316 - mse: 56.1316\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 56.4747 - mse: 56.4747\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 56.5324 - mse: 56.5324\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 54.9039 - mse: 54.9039\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 54.1114 - mse: 54.1114\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 53.9787 - mse: 53.9787\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 54.7010 - mse: 54.7010\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 52.9719 - mse: 52.9719\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 52.4097 - mse: 52.4097\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 52.2963 - mse: 52.2963\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 52.4845 - mse: 52.4845\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 52.1606 - mse: 52.1606\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 51.2703 - mse: 51.2703\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 52.6797 - mse: 52.6797\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 50.6347 - mse: 50.6347\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 49.6947 - mse: 49.6947\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 49.2230 - mse: 49.2230\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 48.8189 - mse: 48.8189\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 48.3316 - mse: 48.3316\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 47.8745 - mse: 47.8745\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 47.4516 - mse: 47.4516\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 48.9439 - mse: 48.9439\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 46.9549 - mse: 46.9549\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 46.3117 - mse: 46.3117\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 46.0565 - mse: 46.0565\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 45.6983 - mse: 45.6983\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 45.1882 - mse: 45.1882\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 45.9007 - mse: 45.9007\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 44.7796 - mse: 44.7796\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 46.8281 - mse: 46.8281\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 43.7168 - mse: 43.7168\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 43.4816 - mse: 43.4816\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 42.9859 - mse: 42.9859\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 42.6109 - mse: 42.6109\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 42.1865 - mse: 42.1865\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 41.8474 - mse: 41.8474\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 41.7322 - mse: 41.7322\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 41.1353 - mse: 41.1353\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 40.9431 - mse: 40.9431\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 40.3395 - mse: 40.3395\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 40.1589 - mse: 40.1589\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 39.6522 - mse: 39.6522\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 39.4274 - mse: 39.4274\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 38.9264 - mse: 38.9264\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 38.2851 - mse: 38.2851\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 37.9481 - mse: 37.9481\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 38.6105 - mse: 38.6105\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 37.3998 - mse: 37.3998\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 37.1847 - mse: 37.1847\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 37.2623 - mse: 37.2623\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 36.3308 - mse: 36.3308\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 35.7027 - mse: 35.7027\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 36.1688 - mse: 36.1688\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 35.3119 - mse: 35.3119\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 34.6976 - mse: 34.6976\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 34.5460 - mse: 34.5460\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 35.3368 - mse: 35.3368\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 33.9139 - mse: 33.9139\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.2088 - mse: 33.2088\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.8398 - mse: 32.8398\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.9292 - mse: 32.9292\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.1642 - mse: 33.1642\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 35.2116 - mse: 35.2116\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.0858 - mse: 32.0858\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 31.2555 - mse: 31.2555\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 31.0800 - mse: 31.0800\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 31.9320 - mse: 31.9320\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.7141 - mse: 30.7141\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.1219 - mse: 30.1219\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 29.8847 - mse: 29.8847\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 30.0407 - mse: 30.0407\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 29.5809 - mse: 29.5809\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.9404 - mse: 28.9404\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.6498 - mse: 28.6498\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 28.3611 - mse: 28.3611\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 28.0250 - mse: 28.0250\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 28.1074 - mse: 28.1074\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.5880 - mse: 27.5880\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.0712 - mse: 27.0712\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.7605 - mse: 26.7605\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.6049 - mse: 26.6049\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 26.0131 - mse: 26.0131\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.9413 - mse: 26.9413\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 27.4284 - mse: 27.4284\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 25.5685 - mse: 25.5685\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 26.0105 - mse: 26.0105\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.4477 - mse: 26.4477\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.8712 - mse: 24.8712\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.1950 - mse: 24.1950\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 24.8044 - mse: 24.8044\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.0319 - mse: 24.0319\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.9132 - mse: 23.9132\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 23.4610 - mse: 23.4610\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.0927 - mse: 23.0927\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.7867 - mse: 22.7867\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.7000 - mse: 22.7000\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.8816 - mse: 22.8816\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.1553 - mse: 22.1553\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.9083 - mse: 21.9083\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.5437 - mse: 21.5437\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.3925 - mse: 21.3925\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.2825 - mse: 21.2825\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 21.2394 - mse: 21.2394\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 20.5650 - mse: 20.5650\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.2261 - mse: 21.2261\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.5697 - mse: 20.5697\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.7720 - mse: 19.7720\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.8907 - mse: 19.8907\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.7661 - mse: 19.7661\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.0411 - mse: 19.0411\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.8200 - mse: 20.8200\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.0461 - mse: 19.0461\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.8241 - mse: 18.8241\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 18.4129 - mse: 18.4129\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.0910 - mse: 18.0910\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.4931 - mse: 18.4931\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.6936 - mse: 18.6936\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.5958 - mse: 17.5958\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.2157 - mse: 17.2157\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.9814 - mse: 16.9814\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.6828 - mse: 16.6828\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.1410 - mse: 17.1410\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.6381 - mse: 16.6381\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0892 - mse: 16.0892\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.0756 - mse: 16.0756\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.8184 - mse: 15.8184\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.0104 - mse: 16.0104\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.3358 - mse: 15.3358\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.1908 - mse: 15.1908\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.6262 - mse: 15.6262\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9817 - mse: 15.9817\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6538 - mse: 14.6538\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.0118 - mse: 15.0118\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.4430 - mse: 14.4430\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.9567 - mse: 13.9567\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.8010 - mse: 13.8010\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.7515 - mse: 13.7515\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.5772 - mse: 14.5772\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.3963 - mse: 13.3963\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.7799 - mse: 14.7799\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.4640 - mse: 13.4640\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.9907 - mse: 14.9907\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.0986 - mse: 13.0986\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.9387 - mse: 13.9387\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.1175 - mse: 13.1175\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4230 - mse: 12.4230\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.2026 - mse: 12.2026\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1869 - mse: 12.1869\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.6668 - mse: 13.6668\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.2369 - mse: 12.2369\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.8068 - mse: 11.8068\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7141 - mse: 11.7141\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.1788 - mse: 12.1788\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6798 - mse: 11.6798\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.8207 - mse: 11.8207\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.5222 - mse: 11.5222\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.9188 - mse: 10.9188\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0735 - mse: 11.0735\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.7748 - mse: 10.7748\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.5311 - mse: 10.5311\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.3994 - mse: 10.3994\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2983 - mse: 10.2983\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.0512 - mse: 11.0512\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8186 - mse: 10.8186\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9738 - mse: 9.9738\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.7809 - mse: 9.7809\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5313 - mse: 10.5313\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.9345 - mse: 9.9345\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6906 - mse: 10.6906\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7488 - mse: 9.7488\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1565 - mse: 10.1565\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5413 - mse: 9.5413\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.7327 - mse: 9.7327\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.3856 - mse: 9.3856\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1378 - mse: 9.1378\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2698 - mse: 9.2698\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7424 - mse: 8.7424\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9553 - mse: 8.9553\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1312 - mse: 9.1312\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3705 - mse: 8.3705\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3286 - mse: 8.3286\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3100 - mse: 8.3100\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.2858 - mse: 8.2858\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3077 - mse: 8.3077\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1868 - mse: 8.1868\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3267 - mse: 9.3267\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4014 - mse: 9.4014\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.1482 - mse: 8.1482\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.8239 - mse: 7.8239\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.5519 - mse: 7.5519\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6882 - mse: 7.6882\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.9534 - mse: 7.9534\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.2733 - mse: 7.2733\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.3794 - mse: 8.3794\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.1668 - mse: 8.1668\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2034 - mse: 7.2034\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0353 - mse: 7.0353\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.9950 - mse: 6.9950\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1010 - mse: 7.1010\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7610 - mse: 6.7610\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7166 - mse: 6.7166\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.6890 - mse: 6.6890\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6142 - mse: 6.6142\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6565 - mse: 6.6565\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.8846 - mse: 7.8846\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.5111 - mse: 6.5111\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.2788 - mse: 7.2788\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3892 - mse: 6.3892\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.2422 - mse: 6.2422\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 6.0809 - mse: 6.0809\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.6890 - mse: 6.6890\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9625 - mse: 5.9625\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9714 - mse: 5.9714\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.7853 - mse: 5.7853\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.7488 - mse: 5.7488\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.6965 - mse: 5.6965\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.5395 - mse: 5.5395\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.9917 - mse: 5.9917\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.9468 - mse: 5.9468\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4749 - mse: 6.4749\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.8966 - mse: 5.8966\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.3332 - mse: 5.3332\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.3886 - mse: 5.3886\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2472 - mse: 5.2472\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.1450 - mse: 5.1450\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.1910 - mse: 5.1910\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4712 - mse: 5.4712\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3510 - mse: 7.3510\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.3347 - mse: 5.3347\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.9720 - mse: 4.9720\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.1849 - mse: 5.1849\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.1047 - mse: 5.1047\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.9914 - mse: 4.9914\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.3964 - mse: 5.3964\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.5588 - mse: 5.5588\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.6793 - mse: 4.6793\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.7592 - mse: 4.7592\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.8744 - mse: 4.8744\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2620 - mse: 5.2620\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.2690 - mse: 5.2690\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.6135 - mse: 4.6135\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.4951 - mse: 4.4951\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.2190 - mse: 5.2190\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.7910 - mse: 4.7910\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.5710 - mse: 4.5710\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.2622 - mse: 4.2622\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.4398 - mse: 4.4398\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.2618 - mse: 4.2618\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.4406 - mse: 5.4406\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.7743 - mse: 4.7743\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.0289 - mse: 5.0289\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3883 - mse: 4.3883\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.0384 - mse: 4.0384\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.0696 - mse: 4.0696\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.0067 - mse: 4.0067\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0921 - mse: 4.0921\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.7787 - mse: 4.7787\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.4908 - mse: 5.4908\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1140 - mse: 4.1140\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0176 - mse: 4.0176\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7978 - mse: 3.7978\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0725 - mse: 4.0725\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1027 - mse: 4.1027\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8961 - mse: 3.8961\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9649 - mse: 3.9649\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.1308 - mse: 4.1308\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 5.0347 - mse: 5.0347\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1755 - mse: 4.1755\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.8569 - mse: 3.8569\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.3578 - mse: 4.3578\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6225 - mse: 3.6225\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.8888 - mse: 3.8888\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4937 - mse: 3.4937\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7543 - mse: 3.7543\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9662 - mse: 3.9662\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.5235 - mse: 3.5235\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7644 - mse: 3.7644\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.3824 - mse: 5.3824\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7153 - mse: 3.7153\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.3525 - mse: 3.3525\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3154 - mse: 3.3154\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3022 - mse: 3.3022\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.3381 - mse: 4.3381\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0960 - mse: 4.0960\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3256 - mse: 3.3256\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3845 - mse: 3.3845\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.9791 - mse: 3.9791\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2309 - mse: 3.2309\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.5222 - mse: 3.5222\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1981 - mse: 3.1981\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1589 - mse: 3.1589\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8599 - mse: 3.8599\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1146 - mse: 3.1146\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4457 - mse: 3.4457\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.2120 - mse: 3.2120\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2830 - mse: 3.2830\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1721 - mse: 3.1721\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9401 - mse: 3.9401\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.0440 - mse: 4.0440\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2912 - mse: 3.2912\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.2084 - mse: 3.2084\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0397 - mse: 3.0397\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9759 - mse: 2.9759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29ca63d90>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 12:02:20.228034: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[20.347652]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00474994, -0.64237976,  1.1920326 ],\n",
       "        [-1.2127967 ,  0.4484758 ,  0.6197462 ],\n",
       "        [-0.33858827, -0.87694556,  0.41806898],\n",
       "        [-0.12903698, -0.16669346,  1.3946134 ],\n",
       "        [-0.03923831,  0.09821993,  0.20969498],\n",
       "        [ 0.1967846 , -0.4257857 , -0.05001729]], dtype=float32),\n",
       " array([-0.4092937 , -0.01713243,  0.40597132], dtype=float32),\n",
       " array([[-0.41592214],\n",
       "        [-0.30333582],\n",
       "        [ 0.05561225]], dtype=float32),\n",
       " array([0.41351485], dtype=float32)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>20.347652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>18.540888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>17.672066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>21.784229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>15.491752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8   20.347652\n",
       "AK       18.1   18.540888\n",
       "AZ       18.6   17.672066\n",
       "AR       22.4   21.784229\n",
       "CA       12.0   15.491752"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8019322160465046"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tanh` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 22:28:29.829058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17e9383a0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 22:28:33.915684: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99999994]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.512019  , -1.0657645 ,  0.9369474 ],\n",
       "        [-0.87672853, -0.54201865,  0.3476844 ],\n",
       "        [-0.19562808, -1.6509485 ,  0.7531322 ],\n",
       "        [-0.5743747 , -0.20604783,  1.8262724 ],\n",
       "        [-1.5198137 , -1.412379  ,  0.6972853 ],\n",
       "        [-0.70423585, -1.3741283 ,  1.6405212 ]], dtype=float32),\n",
       " array([-0.99589634, -0.9827833 ,  0.97375315], dtype=float32),\n",
       " array([[-2.1899748],\n",
       "        [-1.4041648],\n",
       "        [ 1.2513814]], dtype=float32),\n",
       " array([0.97996116], dtype=float32)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         1.0\n",
       "AK       18.1         1.0\n",
       "AZ       18.6         1.0\n",
       "AR       22.4         1.0\n",
       "CA       12.0         1.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.4076488219523"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `relu` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 22:28:37.204348: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17e952310>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-14 22:28:41.186601: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.49556875, -0.6359177 , -0.7493128 ],\n",
       "        [-0.49504453, -0.5848135 , -0.17635965],\n",
       "        [ 0.7622068 , -0.3158698 , -0.5919111 ],\n",
       "        [ 0.58445394,  0.02325135,  0.15200901],\n",
       "        [ 0.01221597, -0.57732755,  0.5594759 ],\n",
       "        [ 0.23276758, -0.1779086 , -0.44693196]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-0.70902157],\n",
       "        [ 0.25331163],\n",
       "        [ 0.29283333]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         0.0\n",
       "AK       18.1         0.0\n",
       "AZ       18.6         0.0\n",
       "AR       22.4         0.0\n",
       "CA       12.0         0.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265.9880392156863"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How are the predictions changing? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizers comparison in GIF ‚Üí https://mlfromscratch.com/optimizers-explained/#adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesla's Neural Network Models is composed of 48 models trainned in 70.000 hours of GPU ‚Üí https://tesla.com/ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Year with a 8 GPU Computer ‚Üí https://twitter.com/thirdrowtesla/status/1252723358342377472"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Gradient Descent `sgd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 262551537171700908032.0000 - mse: 262551537171700908032.0000\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: nan - mse: nan\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: nan - mse: nan\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: nan - mse: nan\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: nan - mse: nan\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: nan - mse: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18f9e6cd0>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.49556875, -0.6359177 , -0.7493128 ],\n",
       "        [-0.49504453, -0.5848135 , -0.17635965],\n",
       "        [ 0.7622068 , -0.3158698 , -0.5919111 ],\n",
       "        [ 0.58445394,  0.02325135,  0.15200901],\n",
       "        [ 0.01221597, -0.57732755,  0.5594759 ],\n",
       "        [ 0.23276758, -0.1779086 , -0.44693196]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[-0.70902157],\n",
       "        [ 0.25331163],\n",
       "        [ 0.29283333]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         0.0\n",
       "AK       18.1         0.0\n",
       "AZ       18.6         0.0\n",
       "AR       22.4         0.0\n",
       "CA       12.0         0.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265.9880392156863"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_85163/763455777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=500, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00470084, -0.31133795, -0.5857754 ],\n",
       "        [-0.44991815,  0.06277943,  0.42929566],\n",
       "        [-0.58053666,  0.27017844,  0.68008864],\n",
       "        [ 0.08229119, -0.5569217 ,  0.06303853],\n",
       "        [-0.5103425 ,  0.04528171, -0.27955174],\n",
       "        [ 0.16269958,  0.09554011,  0.55522823]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[0.2700621],\n",
       "        [0.5750053],\n",
       "        [0.6719738]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros\n",
       "abbrev                   \n",
       "AL       18.8         0.0\n",
       "AK       18.1         0.0\n",
       "AZ       18.6         0.0\n",
       "AR       22.4         0.0\n",
       "CA       12.0         0.0"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = df[['total']].copy()\n",
    "dfres['pred_zeros'] = y_pred\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfres.total - dfres.pred_zeros)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it take different times to get the best accuracy? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The number of Neurons & Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.87287&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to improve the Neural Network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - The Neural Network is horrible because\n",
    "> - We didn't move the randomly initialized weights\n",
    "> - If we get to `fit()` the Neural Network,\n",
    "> - It will probably improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How good is the Model now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the predictions\n",
    "> 2. Give the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Mathematical Formula\n",
    "- Weights / Kernel Initializer\n",
    "- Loss Function\n",
    "- Activation Function\n",
    "- Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What cannot you change arbitrarily of a Neural Network?\n",
    "\n",
    "- Input Neurons\n",
    "- Output Neurons\n",
    "- Loss Functions\n",
    "- Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Another Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2f954b8bdaf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfashion_mnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfashion_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize One Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Which type of clothing is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the Model predicts for this Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Could we improve the Classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `loss` Function Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `activation` Function Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Number of `epochs` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `optimizer` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `kernel_initializer` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Jes√∫s L√≥pez @sotastica"
   }
  ],
  "kernelspec": {
   "display_name": "DeepLearning Python",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
